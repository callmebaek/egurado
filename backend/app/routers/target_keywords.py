"""
íƒ€ê²Ÿ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì§„ë‹¨ API ë¼ìš°í„°
"""
from fastapi import APIRouter, HTTPException, status, Depends
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from uuid import UUID
import logging

from app.services.naver_target_keyword_service import NaverTargetKeywordService
from app.core.database import get_supabase_client
from app.routers.auth import get_current_user
from app.services.credit_service import credit_service
from app.core.config import settings

router = APIRouter()
logger = logging.getLogger(__name__)


class TargetKeywordAnalysisRequest(BaseModel):
    """íƒ€ê²Ÿ í‚¤ì›Œë“œ ë¶„ì„ ìš”ì²­"""
    store_id: str = Field(..., description="ë§¤ì¥ ID")
    # user_id: UUID = Field(..., description="ì‚¬ìš©ì ID")  # Removed: user_id is now extracted from current_user
    regions: List[str] = Field(default=[], description="ì§€ì—­ëª… ë¦¬ìŠ¤íŠ¸")
    landmarks: List[str] = Field(default=[], description="ëœë“œë§ˆí¬ ë¦¬ìŠ¤íŠ¸")
    menus: List[str] = Field(default=[], description="ë©”ë‰´/ìƒí’ˆëª… ë¦¬ìŠ¤íŠ¸")
    industries: List[str] = Field(default=[], description="ì—…ì¢… ë¦¬ìŠ¤íŠ¸")
    others: List[str] = Field(default=[], description="ê¸°íƒ€ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸")


@router.post("/analyze")
async def analyze_target_keywords(
    request: TargetKeywordAnalysisRequest,
    current_user: dict = Depends(get_current_user)
):
    """
    íƒ€ê²Ÿ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ì§„ë‹¨
    
    - ì…ë ¥ëœ í‚¤ì›Œë“œë¥¼ ì¡°í•©í•˜ì—¬ íƒ€ê²Ÿ í‚¤ì›Œë“œ ìƒì„±
    - ê° í‚¤ì›Œë“œì˜ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ
    - ìƒìœ„ 20ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ
    - ë§¤ì¥ì˜ SEO ìµœì í™” ìƒíƒœ ë¶„ì„
    - íˆìŠ¤í† ë¦¬ ì €ì¥ (ë§¤ì¥ë³„ ìµœëŒ€ 10ê°œ, ì´ˆê³¼ ì‹œ ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ ì‚­ì œ)
    í¬ë ˆë”§: 20 í¬ë ˆë”§ ì†Œëª¨
    
    Args:
        request: ë¶„ì„ ìš”ì²­ ë°ì´í„°
        
    Returns:
        ë¶„ì„ ê²°ê³¼ (history_id í¬í•¨)
        
    Raises:
        HTTPException: ë¶„ì„ ì‹¤íŒ¨ ì‹œ
    """
    user_id = UUID(current_user["id"])
    
    try:
        # ğŸ†• í¬ë ˆë”§ ì²´í¬ (Feature Flag í™•ì¸)
        if settings.CREDIT_SYSTEM_ENABLED and settings.CREDIT_CHECK_STRICT:
            check_result = await credit_service.check_sufficient_credits(
                user_id=user_id,
                feature="target_keyword_extraction",
                required_credits=20
            )
            
            if not check_result.sufficient:
                logger.warning(f"[Credits] User {user_id} has insufficient credits for target keyword extraction")
                raise HTTPException(
                    status_code=status.HTTP_402_PAYMENT_REQUIRED,
                    detail="í¬ë ˆë”§ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. í¬ë ˆë”§ì„ ì¶©ì „í•˜ê±°ë‚˜ í”Œëœì„ ì—…ê·¸ë ˆì´ë“œí•´ì£¼ì„¸ìš”."
                )
            
            logger.info(f"[Credits] User {user_id} has sufficient credits for target keyword extraction")
        
        logger.info(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ API] ìš”ì²­ ë°›ìŒ: store_id={request.store_id}, user_id={user_id}")  # Modified: use user_id from current_user
        logger.info(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ API] ì…ë ¥ í‚¤ì›Œë“œ: regions={request.regions}, landmarks={request.landmarks}, menus={request.menus}, industries={request.industries}, others={request.others}")
        
        service = NaverTargetKeywordService()
        
        result = await service.analyze_target_keywords(
            store_id=request.store_id,
            user_id=str(user_id),  # Modified: use user_id from current_user
            regions=request.regions,
            landmarks=request.landmarks,
            menus=request.menus,
            industries=request.industries,
            others=request.others
        )
        
        if result.get("status") == "error":
            logger.error(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ API] ì—ëŸ¬ ë°œìƒ: {result.get('message')}")
            raise HTTPException(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                detail=result.get("message")
            )
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        history_id = None
        try:
            supabase = get_supabase_client()
            data = result.get("data", {})
            store_info = data.get("store_info", {})
            rank_data = data.get("rank_data", {})
            
            # ì¶”ì¶œëœ í‚¤ì›Œë“œë“¤ (ìˆœìœ„ ì •ë³´ í¬í•¨)
            extracted_keywords = []
            for kw in data.get("top_keywords", []):
                keyword_text = kw.get("keyword")
                rank_info = rank_data.get(keyword_text, {})
                
                extracted_keywords.append({
                    "keyword": keyword_text,
                    "total_volume": kw.get("total_volume"),
                    "comp_idx": kw.get("comp_idx"),
                    "rank": rank_info.get("rank", 0),
                    "total_count": rank_info.get("total_count", 0)
                })
            
            # íˆìŠ¤í† ë¦¬ ë°ì´í„° êµ¬ì„±
            history_data = {
                "user_id": str(request.user_id),
                "store_id": request.store_id,
                "store_name": store_info.get("store_name", "Unknown"),
                "regions": request.regions,
                "landmarks": request.landmarks,
                "menus": request.menus,
                "industries": request.industries,
                "other_keywords": request.others,
                "extracted_keywords": extracted_keywords,
                "total_keywords": len(extracted_keywords)
            }
            
            # íˆìŠ¤í† ë¦¬ ì €ì¥
            insert_result = supabase.table("target_keywords_history").insert(history_data).execute()
            
            if insert_result.data and len(insert_result.data) > 0:
                history_id = insert_result.data[0].get("id")
                logger.info(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬] ì €ì¥ ì™„ë£Œ: history_id={history_id}")
                
                # ë§¤ì¥ë³„ íˆìŠ¤í† ë¦¬ ê°œìˆ˜ í™•ì¸ ë° ì˜¤ë˜ëœ ê²ƒ ì‚­ì œ (10ê°œ ì œí•œ)
                history_count_result = supabase.table("target_keywords_history") \
                    .select("id", count="exact") \
                    .eq("store_id", request.store_id) \
                    .execute()
                
                history_count = history_count_result.count if history_count_result.count else 0
                logger.info(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬] ë§¤ì¥ {request.store_id}ì˜ íˆìŠ¤í† ë¦¬ ê°œìˆ˜: {history_count}")
                
                if history_count > 10:
                    # ê°€ì¥ ì˜¤ë˜ëœ ê²ƒ ì‚­ì œ (10ê°œ ì´ˆê³¼ë¶„)
                    to_delete_count = history_count - 10
                    oldest_result = supabase.table("target_keywords_history") \
                        .select("id") \
                        .eq("store_id", request.store_id) \
                        .order("created_at", desc=False) \
                        .limit(to_delete_count) \
                        .execute()
                    
                    if oldest_result.data:
                        ids_to_delete = [item["id"] for item in oldest_result.data]
                        for delete_id in ids_to_delete:
                            supabase.table("target_keywords_history").delete().eq("id", delete_id).execute()
                        logger.info(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬] {to_delete_count}ê°œ ì˜¤ë˜ëœ íˆìŠ¤í† ë¦¬ ì‚­ì œ ì™„ë£Œ")
            else:
                logger.warning(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬] ì €ì¥ì€ ë˜ì—ˆìœ¼ë‚˜ IDë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ")
                
        except Exception as e:
            logger.error(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬] ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            # íˆìŠ¤í† ë¦¬ ì €ì¥ ì‹¤íŒ¨ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
        
        # ì‘ë‹µì— history_id ì¶”ê°€
        if history_id:
            result["history_id"] = history_id
        
        # ğŸ†• í¬ë ˆë”§ ì°¨ê° (ì„±ê³µ ì‹œ)
        if settings.CREDIT_SYSTEM_ENABLED and settings.CREDIT_AUTO_DEDUCT:
            try:
                transaction_id = await credit_service.deduct_credits(
                    user_id=user_id,
                    feature="target_keyword_extraction",
                    credits_amount=20,
                    metadata={
                        "store_id": request.store_id,
                        "keywords_count": len(result.get('data', {}).get('top_keywords', [])),
                        "history_id": history_id
                    }
                )
                logger.info(f"[Credits] Deducted 20 credits from user {user_id} (transaction: {transaction_id})")
            except Exception as credit_error:
                logger.error(f"[Credits] Failed to deduct credits: {credit_error}")
        
        logger.info(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ API] ë¶„ì„ ì™„ë£Œ: {len(result.get('data', {}).get('top_keywords', []))}ê°œ í‚¤ì›Œë“œ")
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"íƒ€ê²Ÿ í‚¤ì›Œë“œ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        )


@router.get("/history/{store_id}")
async def get_store_keyword_history(
    store_id: str,
    current_user: dict = Depends(get_current_user)
):
    """
    ë§¤ì¥ë³„ íƒ€ê²Ÿ í‚¤ì›Œë“œ ì¶”ì¶œ íˆìŠ¤í† ë¦¬ ì¡°íšŒ
    
    Args:
        store_id: ë§¤ì¥ ID
        current_user: í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´
        
    Returns:
        íˆìŠ¤í† ë¦¬ ëª©ë¡ (ìµœì‹ ìˆœ, ìµœëŒ€ 10ê°œ)
    """
    try:
        supabase = get_supabase_client()
        user_id = current_user.get("id")
        
        # ì‚¬ìš©ìì˜ ë§¤ì¥ì¸ì§€ í™•ì¸
        store_check = supabase.table("stores") \
            .select("id") \
            .eq("id", store_id) \
            .eq("user_id", user_id) \
            .single() \
            .execute()
        
        if not store_check.data:
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail="í•´ë‹¹ ë§¤ì¥ì— ëŒ€í•œ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤."
            )
        
        # íˆìŠ¤í† ë¦¬ ì¡°íšŒ (ìµœì‹ ìˆœ, ìµœëŒ€ 10ê°œ)
        result = supabase.table("target_keywords_history") \
            .select("*") \
            .eq("store_id", store_id) \
            .order("created_at", desc=True) \
            .limit(10) \
            .execute()
        
        histories = result.data if result.data else []
        
        logger.info(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬] ì¡°íšŒ ì™„ë£Œ: store_id={store_id}, count={len(histories)}")
        
        # ë””ë²„ê¹…: ì²« ë²ˆì§¸ íˆìŠ¤í† ë¦¬ì˜ í‚¤ í™•ì¸
        if histories:
            logger.info(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬] ì²« ë²ˆì§¸ íˆìŠ¤í† ë¦¬ í‚¤: {list(histories[0].keys())}")
            logger.info(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬] extracted_keywords ì¡´ì¬ ì—¬ë¶€: {'extracted_keywords' in histories[0]}")
            if 'extracted_keywords' in histories[0]:
                logger.info(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬] extracted_keywords ê°’: {histories[0]['extracted_keywords']}")
        
        return {
            "status": "success",
            "store_id": store_id,
            "histories": histories
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬] ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"íˆìŠ¤í† ë¦¬ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        )


@router.get("/history/detail/{history_id}")
async def get_keyword_history_detail(
    history_id: str,
    current_user: dict = Depends(get_current_user)
):
    """
    íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬ ìƒì„¸ ì¡°íšŒ
    
    Args:
        history_id: íˆìŠ¤í† ë¦¬ ID
        current_user: í˜„ì¬ ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ì •ë³´
        
    Returns:
        íˆìŠ¤í† ë¦¬ ìƒì„¸ ì •ë³´ (ì¶”ì¶œëœ í‚¤ì›Œë“œ í¬í•¨)
    """
    try:
        supabase = get_supabase_client()
        user_id = current_user.get("id")
        
        # íˆìŠ¤í† ë¦¬ ì¡°íšŒ (ì‚¬ìš©ì ì†Œìœ  í™•ì¸)
        result = supabase.table("target_keywords_history") \
            .select("*") \
            .eq("id", history_id) \
            .eq("user_id", user_id) \
            .single() \
            .execute()
        
        if not result.data:
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail="íˆìŠ¤í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )
        
        history = result.data
        
        logger.info(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬] ìƒì„¸ ì¡°íšŒ ì™„ë£Œ: history_id={history_id}")
        
        return {
            "status": "success",
            "history": history
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[íƒ€ê²Ÿ í‚¤ì›Œë“œ íˆìŠ¤í† ë¦¬] ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"íˆìŠ¤í† ë¦¬ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"
        )
