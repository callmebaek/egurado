"""
Naver Place Rank Service (ì‹ API ë°©ì‹)
ë„¤ì´ë²„ GraphQL APIë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ê³ ì† ìˆœìœ„ ì²´í¬ ì„œë¹„ìŠ¤

âš ï¸ ê²½ê³ : ì´ ì½”ë“œëŠ” ë„¤ì´ë²„ì˜ ë‚´ë¶€ APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
         êµìœ¡ ëª©ì ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ì„¸ìš”.

ì‹¤ì œ êµ¬í˜„: ë„¤ì´ë²„ê°€ ì‚¬ìš©í•˜ëŠ” GraphQL APIë¥¼ ì§ì ‘ í˜¸ì¶œ (ë¹ ë¦„!)

ğŸ›¡ï¸ í´ë°± ì „ëµ:
1ì°¨: í”„ë¡ì‹œ ê²½ìœ  â†’ 2ì°¨: ì§ì ‘ ì—°ê²° â†’ 3ì°¨: Playwright í¬ë¡¤ë§
"""
import logging
import httpx
import json
from typing import Dict, List, Optional
import asyncio
from app.core.proxy import get_proxy, report_proxy_success, report_proxy_failure

logger = logging.getLogger(__name__)


class NaverRankNewAPIService:
    """ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ì‹ API ìˆœìœ„ ì²´í¬ ì„œë¹„ìŠ¤ (GraphQL ì§ì ‘ í˜¸ì¶œ)
    
    ë„¤ì´ë²„ ë‚´ë¶€ GraphQL APIë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ë¹ ë¥¸ ìˆœìœ„ í™•ì¸ ì œê³µ
    
    ğŸ›¡ï¸ 3ë‹¨ê³„ í´ë°±:
    1. í”„ë¡ì‹œ ê²½ìœ  ìš”ì²­
    2. í”„ë¡ì‹œ ì‹¤íŒ¨ ì‹œ ì§ì ‘ ì—°ê²° ì¬ì‹œë„
    3. ëª¨ë‘ ì‹¤íŒ¨ ì‹œ Playwright í¬ë¡¤ë§ í´ë°±
    """
    
    def __init__(self):
        # ë„¤ì´ë²„ ì‹¤ì œ GraphQL API ì—”ë“œí¬ì¸íŠ¸
        self.api_url = "https://api.place.naver.com/graphql"
        
        # í•„ìˆ˜ í—¤ë”
        self.base_headers = {
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1",
            "Accept": "application/json, text/plain, */*",
            "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
            "Content-Type": "application/json",
            "Origin": "https://m.place.naver.com",
            "Referer": "https://m.place.naver.com/",
            "sec-ch-ua": '"Not_A Brand";v="8", "Chromium";v="120"',
            "sec-ch-ua-mobile": "?1",
            "sec-ch-ua-platform": '"iOS"',
            "sec-fetch-dest": "empty",
            "sec-fetch-mode": "cors",
            "sec-fetch-site": "same-site",
        }
        
        self.timeout = 15.0
        
    async def check_rank(
        self, 
        keyword: str, 
        target_place_id: str,
        max_results: int = 300,
        store_name: str = None,
        coord_x: str = None,
        coord_y: str = None
    ) -> Dict:
        """
        íŠ¹ì • í‚¤ì›Œë“œì—ì„œ ë§¤ì¥ì˜ ìˆœìœ„ í™•ì¸ (ì‹ API - ë¹ ë¦„!)
        
        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            target_place_id: ì°¾ì„ ë§¤ì¥ì˜ Place ID
            max_results: ìµœëŒ€ í™•ì¸ ê°œìˆ˜ (ê¸°ë³¸ 300ê°œ)
            store_name: ë§¤ì¥ëª… (300ìœ„ ë°–ì¼ ë•Œ ë¦¬ë·° ìˆ˜ ì¡°íšŒì— ì‚¬ìš©)
            coord_x: ê²½ë„ (300ìœ„ ë°–ì¼ ë•Œ ë¦¬ë·° ìˆ˜ ì¡°íšŒì— ì‚¬ìš©)
            coord_y: ìœ„ë„ (300ìœ„ ë°–ì¼ ë•Œ ë¦¬ë·° ìˆ˜ ì¡°íšŒì— ì‚¬ìš©)
            
        Returns:
            {
                'rank': int ë˜ëŠ” None (ìˆœìœ„),
                'total_results': int (ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜),
                'total_count': str (ì „ì²´ ì—…ì²´ ìˆ˜, ì˜ˆ: "1,234"),
                'found': bool (ë§¤ì¥ ë°œê²¬ ì—¬ë¶€),
                'search_results': List[Dict] (ìˆœìœ„ ë‚´ ëª¨ë“  ë§¤ì¥ ì •ë³´),
                'target_store': Dict (íƒ€ê²Ÿ ë§¤ì¥ì˜ ìƒì„¸ ì •ë³´) - ë¦¬ë·°ìˆ˜ í¬í•¨,
                'visitor_review_count': int (ë°©ë¬¸ì ë¦¬ë·°ìˆ˜),
                'blog_review_count': int (ë¸”ë¡œê·¸ ë¦¬ë·°ìˆ˜),
                'save_count': int (ì €ì¥ ìˆ˜)
            }
        """
        logger.info(f"[ì‹ API Rank] ìˆœìœ„ ì²´í¬ ì‹œì‘: keyword={keyword}, place_id={target_place_id}, store_name={store_name}, x={coord_x}, y={coord_y}")
        
        try:
            # 1. GraphQLë¡œ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (í”„ë¡ì‹œ -> ì§ì ‘ ì—°ê²° í´ë°± í¬í•¨)
            search_results, total_count = await self._search_places_with_fallback(keyword, max_results, coord_x, coord_y)
            
            if not search_results:
                # GraphQLì´ ë¹ˆ ê²°ê³¼ë¥¼ ë°˜í™˜í•œ ê²½ìš° - 2ì´ˆ ëŒ€ê¸° í›„ 1íšŒ ì¬ì‹œë„
                logger.warning(f"[ì‹ API Rank] ê²€ìƒ‰ ê²°ê³¼ 0ê°œ -> 2ì´ˆ í›„ 1íšŒ ì¬ì‹œë„")
                await asyncio.sleep(2)
                search_results, total_count = await self._search_places_with_fallback(keyword, max_results, coord_x, coord_y)
                
                if not search_results:
                    logger.warning(f"[ì‹ API Rank] ì¬ì‹œë„ í›„ì—ë„ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ -> í¬ë¡¤ë§ í´ë°±")
                    raise Exception("GraphQL ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - ì¬ì‹œë„ í¬í•¨ ëª¨ë“  ì—°ê²° ë°©ì‹ ì‹¤íŒ¨")
            
            # 2. ìˆœìœ„ ì°¾ê¸°
            rank = None
            found = False
            target_store_data = {}
            
            for idx, store in enumerate(search_results, start=1):
                if store.get("place_id") == target_place_id:
                    rank = idx
                    found = True
                    # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì´ë¯¸ ë¦¬ë·°ìˆ˜ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŒ
                    target_store_data = {
                        "place_id": target_place_id,
                        "visitor_review_count": store.get("visitor_review_count", 0),
                        "blog_review_count": int(str(store.get("blog_review_count", "0")).replace(",", "")),
                        "save_count": 0  # ê²€ìƒ‰ ê²°ê³¼ì—ëŠ” save_countê°€ ì—†ìœ¼ë¯€ë¡œ 0
                    }
                    
                    # ğŸ”§ ë¦¬ë·° ìˆ˜ê°€ ë‘˜ ë‹¤ 0ì¼ ë•Œ ì¶”ê°€ ì¡°íšŒ (GraphQL ì‘ë‹µì— ëˆ„ë½ëœ ê²½ìš° ëŒ€ë¹„)
                    if target_store_data["visitor_review_count"] == 0 and target_store_data["blog_review_count"] == 0:
                        logger.info(f"[ì‹ API Rank] âš ï¸ ë¦¬ë·° ìˆ˜ê°€ 0, ì¶”ê°€ ì¡°íšŒ ì‹œë„: place_id={target_place_id}")
                        try:
                            place_detail = await self._get_place_detail(target_place_id)
                            if place_detail:
                                target_store_data["visitor_review_count"] = place_detail.get("visitor_review_count", 0)
                                target_store_data["blog_review_count"] = place_detail.get("blog_review_count", 0)
                                target_store_data["save_count"] = place_detail.get("save_count", 0)
                                logger.info(f"[ì‹ API Rank] âœ… ì¶”ê°€ ì¡°íšŒ ì„±ê³µ: ë°©ë¬¸ì={target_store_data['visitor_review_count']}, ë¸”ë¡œê·¸={target_store_data['blog_review_count']}")
                        except Exception as e:
                            logger.warning(f"[ì‹ API Rank] ì¶”ê°€ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
                    
                    break
            
            # 3. ìˆœìœ„ë¥¼ ëª» ì°¾ì•˜ì„ ë•Œ ë§¤ì¥ëª…ìœ¼ë¡œ ë¦¬ë·° ìˆ˜ ì¡°íšŒ
            if not found:
                logger.info(f"[ì‹ API Rank] â­ ìˆœìœ„ ì—†ìŒ(300ìœ„ ë°–), ë§¤ì¥ëª…ìœ¼ë¡œ ë¦¬ë·° ìˆ˜ ì¡°íšŒ ì‹œë„: place_id={target_place_id}, store_name={store_name}")
                try:
                    # naver_review_service ì‚¬ìš© (ë§¤ì¥ëª… ê²€ìƒ‰ ë°©ì‹)
                    from .naver_review_service import NaverReviewService
                    review_service = NaverReviewService()
                    place_info = await review_service.get_place_info(
                        place_id=target_place_id,
                        store_name=store_name,
                        x=coord_x,
                        y=coord_y
                    )
                    
                    if place_info:
                        target_store_data = {
                            "place_id": target_place_id,
                            "visitor_review_count": place_info.get("visitor_review_count", 0),
                            "blog_review_count": place_info.get("blog_review_count", 0),
                            "save_count": 0
                        }
                        logger.info(f"[ì‹ API Rank] âœ… ë§¤ì¥ëª… ê²€ìƒ‰ ì„±ê³µ: ë°©ë¬¸ì={target_store_data['visitor_review_count']}, ë¸”ë¡œê·¸={target_store_data['blog_review_count']}")
                    else:
                        logger.warning(f"[ì‹ API Rank] ë§¤ì¥ ì •ë³´ ì—†ìŒ â†’ ë¦¬ë·°ìˆ˜ 0ìœ¼ë¡œ ì„¤ì •")
                        target_store_data = {
                            "place_id": target_place_id,
                            "visitor_review_count": 0,
                            "blog_review_count": 0,
                            "save_count": 0
                        }
                except Exception as e:
                    logger.error(f"[ì‹ API Rank] âŒ ë§¤ì¥ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
                    target_store_data = {
                        "place_id": target_place_id,
                        "visitor_review_count": 0,
                        "blog_review_count": 0,
                        "save_count": 0
                    }
                    logger.warning(f"[ì‹ API Rank] ë§¤ì¥ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ â†’ ë¦¬ë·°ìˆ˜ 0ìœ¼ë¡œ ì„¤ì •")
            
            # 4. ê²°ê³¼ êµ¬ì„±
            result = {
                "rank": rank,
                "total_results": len(search_results),
                "total_count": total_count,  # ì‹¤ì œ ì „ì²´ ì—…ì²´ìˆ˜
                "found": found,
                "search_results": search_results,
                "target_store": target_store_data,
                "visitor_review_count": target_store_data.get("visitor_review_count", 0),
                "blog_review_count": target_store_data.get("blog_review_count", 0),
                "save_count": target_store_data.get("save_count", 0)
            }
            
            logger.info(
                f"[ì‹ API Rank] ê²°ê³¼: Found={found}, Rank={rank}, "
                f"ë°©ë¬¸ìë¦¬ë·°={result['visitor_review_count']}, "
                f"ë¸”ë¡œê·¸ë¦¬ë·°={result['blog_review_count']}, "
                f"ì €ì¥ìˆ˜={result['save_count']}"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"[ì‹ API Rank] ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ì‹œ í¬ë¡¤ë§ ë°©ì‹ìœ¼ë¡œ í´ë°±
            logger.info("[ì‹ API Rank] í¬ë¡¤ë§ ë°©ì‹ìœ¼ë¡œ í´ë°±...")
            return await self._fallback_to_crawling(
                keyword, target_place_id, max_results,
                store_name=store_name, coord_x=coord_x, coord_y=coord_y
            )
    
    async def _search_places_with_fallback(
        self, keyword: str, max_results: int, coord_x: str = None, coord_y: str = None
    ) -> tuple[List[Dict], int]:
        """
        ğŸ›¡ï¸ í˜ì´ì§€ë³„ í”„ë¡ì‹œ â†’ ì§ì ‘ ì—°ê²° ìë™ í´ë°±ì´ í¬í•¨ëœ ê²€ìƒ‰
        
        ê° í˜ì´ì§€ë§ˆë‹¤ ê°œë³„ì ìœ¼ë¡œ í´ë°± ì²˜ë¦¬:
        - í”„ë¡ì‹œë¡œ ì„±ê³µí•œ í˜ì´ì§€ëŠ” ê²°ê³¼ ìœ ì§€
        - í”„ë¡ì‹œ ì‹¤íŒ¨í•œ í˜ì´ì§€ë§Œ ì§ì ‘ ì—°ê²°ë¡œ ì¬ì‹œë„
        - í”„ë¡ì‹œ ì‹¤íŒ¨ ì‹œ ë‚¨ì€ í˜ì´ì§€ë„ ì§ì ‘ ì—°ê²°ë¡œ ì „í™˜ (ë¶ˆí•„ìš”í•œ ì¬ì‹œë„ ë°©ì§€)
        
        Returns:
            (ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸, ì „ì²´ ì—…ì²´ìˆ˜)
        """
        from app.core.proxy import record_request
        
        proxy_url = get_proxy()
        use_proxy = bool(proxy_url)
        
        search_x = coord_x if coord_x else "127.0276"
        search_y = coord_y if coord_y else "37.4979"
        
        if use_proxy:
            logger.info(f"[ì‹ API Rank] í”„ë¡ì‹œ ëª¨ë“œ ì‹œì‘ (í˜ì´ì§€ë³„ í´ë°± í™œì„±)")
        else:
            logger.info(f"[ì‹ API Rank] ì§ì ‘ ì—°ê²° ëª¨ë“œ (í”„ë¡ì‹œ ë¯¸ì„¤ì • ë˜ëŠ” ë¹„í™œì„±)")
        
        logger.info(f"[ì‹ API Rank] ê²€ìƒ‰ ìœ„ì¹˜: x={search_x}, y={search_y}")
        
        all_stores = []
        total_count = 0
        page_size = 100
        proxy_page_successes = 0
        direct_page_successes = 0
        page_num = 0
        
        for start_idx in range(1, max_results + 1, page_size):
            remaining = max_results - len(all_stores)
            if remaining <= 0:
                break
            
            current_display = min(remaining, page_size)
            page_num += 1
            page_data = None
            
            # --- í”„ë¡ì‹œ ì‹œë„ ---
            if use_proxy and proxy_url:
                try:
                    logger.info(f"[ì‹ API Rank] í˜ì´ì§€{page_num} ìš”ì²­: start={start_idx}, display={current_display}, ì—°ê²°=í”„ë¡ì‹œ")
                    page_data = await self._fetch_single_page(
                        keyword, start_idx, current_display, search_x, search_y, proxy_url
                    )
                    proxy_page_successes += 1
                    record_request("proxy", True, page=page_num)
                    logger.info(f"[ì‹ API Rank] í˜ì´ì§€{page_num} í”„ë¡ì‹œ ì„±ê³µ")
                except Exception as e:
                    record_request("proxy", False, page=page_num, error=str(e))
                    logger.warning(f"[ì‹ API Rank] í˜ì´ì§€{page_num} í”„ë¡ì‹œ ì‹¤íŒ¨: {str(e)[:80]} â†’ ì´ í˜ì´ì§€ë¶€í„° ì§ì ‘ ì—°ê²°")
                    use_proxy = False  # ë‚¨ì€ í˜ì´ì§€ë„ ì§ì ‘ ì—°ê²°ë¡œ ì „í™˜
            
            # --- ì§ì ‘ ì—°ê²° í´ë°± (í”„ë¡ì‹œ ì‹¤íŒ¨ ë˜ëŠ” ë¯¸ì„¤ì •) ---
            if page_data is None:
                try:
                    logger.info(f"[ì‹ API Rank] í˜ì´ì§€{page_num} ìš”ì²­: start={start_idx}, display={current_display}, ì—°ê²°=ì§ì ‘")
                    page_data = await self._fetch_single_page(
                        keyword, start_idx, current_display, search_x, search_y, None
                    )
                    direct_page_successes += 1
                    record_request("direct", True, page=page_num)
                    logger.info(f"[ì‹ API Rank] í˜ì´ì§€{page_num} ì§ì ‘ ì—°ê²° ì„±ê³µ")
                except Exception as e:
                    record_request("direct", False, page=page_num, error=str(e))
                    logger.error(f"[ì‹ API Rank] í˜ì´ì§€{page_num} ì§ì ‘ ì—°ê²°ë„ ì‹¤íŒ¨: {str(e)[:80]}")
                    break  # ì§ì ‘ ì—°ê²°ë„ ì‹¤íŒ¨í•˜ë©´ ì¤‘ë‹¨
            
            # --- ë°ì´í„° ì¶”ì¶œ ---
            if start_idx == 1:
                total_count = page_data.get("data", {}).get("places", {}).get("total", 0)
                logger.info(f"[ì‹ API Rank] ì „ì²´ ì—…ì²´ìˆ˜: {total_count}ê°œ")
            
            items = page_data.get("data", {}).get("places", {}).get("items", [])
            if not items:
                logger.info(f"[ì‹ API Rank] ë” ì´ìƒ ê²°ê³¼ ì—†ìŒ (start={start_idx})")
                break
            
            for item in items:
                all_stores.append(self._parse_store_item(item))
            
            logger.info(f"[ì‹ API Rank] ëˆ„ì  ê²°ê³¼: {len(all_stores)}ê°œ")
        
        # --- í”„ë¡ì‹œ ìƒíƒœ ë³´ê³  ---
        if proxy_page_successes > 0:
            report_proxy_success()
        if proxy_page_successes == 0 and proxy_url:
            report_proxy_failure("ëª¨ë“  í˜ì´ì§€ì—ì„œ í”„ë¡ì‹œ ì‹¤íŒ¨")
        
        logger.info(
            f"[ì‹ API Rank] ê²€ìƒ‰ ì™„ë£Œ: ì´ {len(all_stores)}ê°œ, "
            f"í”„ë¡ì‹œ ì„±ê³µ={proxy_page_successes}í˜ì´ì§€, ì§ì ‘ ì„±ê³µ={direct_page_successes}í˜ì´ì§€"
        )
        
        return (all_stores, total_count)
    
    async def _fetch_single_page(
        self, keyword: str, start: int, display: int,
        x: str, y: str, proxy_url: str = None
    ) -> dict:
        """GraphQL ë‹¨ì¼ í˜ì´ì§€ ìš”ì²­
        
        Args:
            keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
            start: ì‹œì‘ ì¸ë±ìŠ¤
            display: ìš”ì²­ ê°œìˆ˜
            x: ê²½ë„
            y: ìœ„ë„
            proxy_url: í”„ë¡ì‹œ URL (Noneì´ë©´ ì§ì ‘ ì—°ê²°)
            
        Returns:
            GraphQL API ì‘ë‹µ JSON
            
        Raises:
            Exception: ìš”ì²­ ì‹¤íŒ¨ ì‹œ (í˜¸ì¶œìê°€ í´ë°± ì²˜ë¦¬)
        """
        graphql_query = """
        query getPlacesList($input: PlacesInput) {
            places(input: $input) {
                total
                items {
                    id
                    name
                    category
                    address
                    roadAddress
                    x
                    y
                    imageUrl
                    blogCafeReviewCount
                    visitorReviewCount
                    visitorReviewScore
                }
            }
        }
        """
        
        variables = {
            "input": {
                "query": keyword,
                "start": start,
                "display": display,
                "deviceType": "mobile",
                "x": x,
                "y": y
            }
        }
        
        payload = {
            "operationName": "getPlacesList",
            "variables": variables,
            "query": graphql_query
        }
        
        # í”„ë¡ì‹œ ì‚¬ìš© ì‹œ íƒ€ì„ì•„ì›ƒ ì—¬ìœ  ìˆê²Œ
        timeout = 20.0 if proxy_url else self.timeout
        client_kwargs = {"timeout": timeout}
        if proxy_url:
            client_kwargs["proxy"] = proxy_url
        
        async with httpx.AsyncClient(**client_kwargs) as client:
            response = await client.post(
                self.api_url,
                json=payload,
                headers=self.base_headers,
                follow_redirects=True
            )
            response.raise_for_status()
            return response.json()
    
    @staticmethod
    def _parse_store_item(item: dict) -> dict:
        """GraphQL ì‘ë‹µì˜ ë§¤ì¥ í•­ëª©ì„ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        def parse_int(value):
            if value is None:
                return 0
            if isinstance(value, int):
                return value
            try:
                return int(str(value).replace(',', ''))
            except (ValueError, AttributeError):
                return 0
        
        def parse_rating(value):
            if value is None or value == "" or value == "None":
                return None
            try:
                rating = float(value)
                return rating if rating > 0 else None
            except (ValueError, TypeError):
                return None
        
        visitor_count = parse_int(item.get("visitorReviewCount"))
        blog_count = parse_int(item.get("blogCafeReviewCount"))
        rating = parse_rating(item.get("visitorReviewScore"))
        
        return {
            "place_id": str(item.get("id", "")),
            "name": item.get("name", ""),
            "category": item.get("category", ""),
            "address": item.get("address", ""),
            "road_address": item.get("roadAddress", ""),
            "phone": "",
            "rating": rating,
            "review_count": str(visitor_count),
            "blog_review_count": str(blog_count),
            "visitor_review_count": visitor_count,
            "thumbnail": item.get("imageUrl", ""),
            "x": str(item.get("x", "")),
            "y": str(item.get("y", ""))
        }
    
    async def _get_place_detail(self, place_id: str) -> Dict:
        """íŠ¹ì • ë§¤ì¥ì˜ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë¦¬ë·°ìˆ˜, ì €ì¥ìˆ˜ ë“±)
        
        ğŸ›¡ï¸ í”„ë¡ì‹œ â†’ ì§ì ‘ ì—°ê²° í´ë°± í¬í•¨
        """
        # í”„ë¡ì‹œ ì‹œë„ â†’ ì§ì ‘ ì—°ê²° í´ë°±
        proxy_url = get_proxy()
        
        if proxy_url:
            try:
                result = await self._get_place_detail_internal(place_id, proxy_url=proxy_url)
                if result:
                    report_proxy_success()
                    return result
            except Exception as e:
                report_proxy_failure(str(e))
                logger.warning(f"[ì‹ API Rank] ìƒì„¸ ì¡°íšŒ í”„ë¡ì‹œ ì‹¤íŒ¨: {str(e)} â†’ ì§ì ‘ ì—°ê²°")
        
        return await self._get_place_detail_internal(place_id, proxy_url=None)
    
    async def _get_place_detail_internal(self, place_id: str, proxy_url: str = None) -> Dict:
        """íŠ¹ì • ë§¤ì¥ì˜ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë‚´ë¶€ êµ¬í˜„)"""
        try:
            logger.info(f"[ì‹ API Rank] _get_place_detail í˜¸ì¶œ: place_id={place_id}")
            
            # ìˆ«ì íŒŒì‹± í—¬í¼ í•¨ìˆ˜
            def parse_int(value):
                """ì‰¼í‘œê°€ í¬í•¨ëœ ë¬¸ìì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜"""
                if value is None:
                    return 0
                if isinstance(value, int):
                    return value
                try:
                    return int(str(value).replace(',', ''))
                except (ValueError, AttributeError):
                    return 0
            
            # Places Search ì¿¼ë¦¬ ì‚¬ìš© (place IDë¡œ ì§ì ‘ ì¡°íšŒ)
            graphql_query = """
            query getPlacesList($input: PlacesInput) {
                places(input: $input) {
                    items {
                        id
                        name
                        visitorReviewCount
                        blogCafeReviewCount
                        bookingReviewCount
                    }
                }
            }
            """
            
            variables = {
                "input": {
                    "query": place_id,
                    "start": 1,
                    "display": 1
                }
            }
            
            payload = {
                "operationName": "getPlacesList",
                "variables": variables,
                "query": graphql_query
            }
            
            logger.info(f"[ì‹ API Rank] GraphQL ìš”ì²­ payload (Places Search): {payload}")
            
            # í”„ë¡ì‹œ ì¡°ê±´ë¶€ ì„¤ì •
            client_kwargs = {"timeout": self.timeout}
            if proxy_url:
                client_kwargs["proxy"] = proxy_url
            
            async with httpx.AsyncClient(**client_kwargs) as client:
                response = await client.post(
                    self.api_url,
                    json=payload,
                    headers=self.base_headers,
                    follow_redirects=True
                )
                
                logger.info(f"[ì‹ API Rank] GraphQL ì‘ë‹µ status: {response.status_code}")
                
                response.raise_for_status()
                data = response.json()
                
                places = data.get("data", {}).get("places", {}).get("items", [])
                
                if not places:
                    logger.warning(f"[ì‹ API Rank] Places Searchì—ì„œ ë§¤ì¥ì„ ì°¾ì§€ ëª»í•¨: place_id={place_id}")
                    return {
                        "visitor_review_count": 0,
                        "blog_review_count": 0,
                        "save_count": 0
                    }
                
                place = places[0]
                
                result = {
                    "visitor_review_count": parse_int(place.get("visitorReviewCount")),
                    "blog_review_count": parse_int(place.get("blogCafeReviewCount")),
                    "save_count": 0,  # Places Searchì—ì„œëŠ” saveCount ì—†ìŒ
                    "booking_review_count": parse_int(place.get("bookingReviewCount"))
                }
                
                logger.info(f"[ì‹ API Rank] âœ… íŒŒì‹± ê²°ê³¼: {result}")
                return result
                
        except Exception as e:
            logger.error(f"[ì‹ API Rank] âŒ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return {
                "visitor_review_count": 0,
                "blog_review_count": 0,
                "save_count": 0
            }
    
    async def _fallback_to_crawling(
        self, 
        keyword: str, 
        target_place_id: str, 
        max_results: int,
        store_name: str = None,
        coord_x: str = None,
        coord_y: str = None
    ) -> Dict:
        """ì‹ API ì‹¤íŒ¨ ì‹œ í¬ë¡¤ë§ ë°©ì‹ìœ¼ë¡œ í´ë°±
        
        í¬ë¡¤ë§ìœ¼ë¡œ ìˆœìœ„ë¥¼ ì°¾ì€ í›„, ë¦¬ë·°ìˆ˜ëŠ” ë³„ë„ APIë¡œ ì¡°íšŒí•˜ì—¬ ë³´ì™„
        """
        try:
            from .naver_rank_service_crawling import rank_service
            logger.info("[ì‹ API Rank -> í¬ë¡¤ë§] í¬ë¡¤ë§ ì„œë¹„ìŠ¤ í˜¸ì¶œ")
            result = await rank_service.check_rank(
                keyword=keyword,
                target_place_id=target_place_id,
                max_results=max_results
            )
            
            # target_store ì •ë³´ ì¶”ê°€
            target_store = {
                "place_id": target_place_id,
                "visitor_review_count": 0,
                "blog_review_count": 0,
                "save_count": 0
            }
            
            # í¬ë¡¤ë§ìœ¼ë¡œ ë§¤ì¥ì„ ì°¾ì•˜ìœ¼ë©´ ë¦¬ë·°ìˆ˜ë¥¼ ë³„ë„ APIë¡œ ì¡°íšŒ
            if result.get("found"):
                logger.info(f"[ì‹ API Rank -> í¬ë¡¤ë§] ë§¤ì¥ ë°œê²¬ (rank={result.get('rank')}), ë¦¬ë·°ìˆ˜ ë³„ë„ ì¡°íšŒ ì‹œì‘")
                try:
                    # 1ì°¨: GraphQL place detailë¡œ ë¦¬ë·°ìˆ˜ ì¡°íšŒ
                    place_detail = await self._get_place_detail(target_place_id)
                    if place_detail and (place_detail.get("visitor_review_count", 0) > 0 or place_detail.get("blog_review_count", 0) > 0):
                        target_store = {
                            "place_id": target_place_id,
                            "visitor_review_count": place_detail.get("visitor_review_count", 0),
                            "blog_review_count": place_detail.get("blog_review_count", 0),
                            "save_count": place_detail.get("save_count", 0)
                        }
                        logger.info(
                            f"[ì‹ API Rank -> í¬ë¡¤ë§] GraphQL ë¦¬ë·°ìˆ˜ ì¡°íšŒ ì„±ê³µ: "
                            f"visitor={target_store['visitor_review_count']}, blog={target_store['blog_review_count']}"
                        )
                    else:
                        # 2ì°¨: naver_review_serviceë¡œ ë¦¬ë·°ìˆ˜ ì¡°íšŒ
                        logger.info("[ì‹ API Rank -> í¬ë¡¤ë§] GraphQL ë¦¬ë·°ìˆ˜ 0, naver_review_serviceë¡œ ì¬ì‹œë„")
                        from .naver_review_service import NaverReviewService
                        review_service = NaverReviewService()
                        place_info = await review_service.get_place_info(
                            place_id=target_place_id,
                            store_name=store_name,
                            x=coord_x,
                            y=coord_y
                        )
                        if place_info:
                            target_store = {
                                "place_id": target_place_id,
                                "visitor_review_count": place_info.get("visitor_review_count", 0),
                                "blog_review_count": place_info.get("blog_review_count", 0),
                                "save_count": 0
                            }
                            logger.info(
                                f"[ì‹ API Rank -> í¬ë¡¤ë§] review_service ë¦¬ë·°ìˆ˜ ì¡°íšŒ ì„±ê³µ: "
                                f"visitor={target_store['visitor_review_count']}, blog={target_store['blog_review_count']}"
                            )
                except Exception as review_err:
                    logger.warning(f"[ì‹ API Rank -> í¬ë¡¤ë§] ë¦¬ë·°ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨ (ìˆœìœ„ëŠ” ìœ íš¨): {str(review_err)}")
            
            result["target_store"] = target_store
            result["visitor_review_count"] = target_store["visitor_review_count"]
            result["blog_review_count"] = target_store["blog_review_count"]
            result["save_count"] = target_store["save_count"]
            
            logger.info(
                f"[ì‹ API Rank -> í¬ë¡¤ë§] ìµœì¢… ê²°ê³¼: rank={result.get('rank')}, "
                f"visitor={target_store['visitor_review_count']}, blog={target_store['blog_review_count']}"
            )
            
            return result
            
        except Exception as e:
            logger.error(f"[ì‹ API Rank -> í¬ë¡¤ë§] í¬ë¡¤ë§ë„ ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"ì‹ APIì™€ í¬ë¡¤ë§ ëª¨ë‘ ì‹¤íŒ¨: {str(e)}")


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
rank_service_new_api = NaverRankNewAPIService()
# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
rank_service_api_unofficial = rank_service_new_api
