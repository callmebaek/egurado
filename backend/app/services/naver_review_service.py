"""
ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·° ì¡°íšŒ ì„œë¹„ìŠ¤
- ë°©ë¬¸ì ë¦¬ë·° (GraphQL API)
- ë¸”ë¡œê·¸ ë¦¬ë·° (GraphQL API)
"""
import httpx
import logging
import pytz
from typing import List, Dict, Optional, Any
from datetime import datetime

logger = logging.getLogger(__name__)


class NaverReviewService:
    """ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ë¦¬ë·° ì¡°íšŒ ì„œë¹„ìŠ¤"""
    
    GRAPHQL_URL = "https://api.place.naver.com/graphql"
    TIMEOUT = 30.0
    
    def __init__(self):
        self.headers = {
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15",
            "Accept": "application/json",
            "Content-Type": "application/json",
            "Origin": "https://m.place.naver.com",
            "Referer": "https://m.place.naver.com/",
        }
    
    async def get_visitor_reviews(
        self, 
        place_id: str, 
        size: int = 20,
        sort: str = "recent",  # recent, popular, high_rating, low_rating
        after: str = None  # Cursor for pagination
    ) -> Dict[str, Any]:
        """
        ë°©ë¬¸ì ë¦¬ë·° ì¡°íšŒ (GraphQL - Cursor ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜)
        
        Args:
            place_id: ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ID
            size: ê°€ì ¸ì˜¬ ë¦¬ë·° ìˆ˜
            sort: ì •ë ¬ ê¸°ì¤€
            after: í˜ì´ì§€ë„¤ì´ì…˜ ì»¤ì„œ (ì´ì „ ì‘ë‹µì˜ ë§ˆì§€ë§‰ ë¦¬ë·° cursor)
        
        Returns:
            {
                "total": ì „ì²´ ë¦¬ë·° ìˆ˜,
                "items": [ë¦¬ë·° ëª©ë¡] (ê° ë¦¬ë·°ì— cursor í¬í•¨),
                "has_more": ë‹¤ìŒ í˜ì´ì§€ ì—¬ë¶€,
                "last_cursor": ë§ˆì§€ë§‰ ë¦¬ë·°ì˜ cursor
            }
        """
        query = """
        query getVisitorReviews($input: VisitorReviewsInput) {
            visitorReviews(input: $input) {
                items {
                    id
                    cursor
                    reviewId
                    rating
                    author {
                        id
                        nickname
                        imageUrl
                    }
                    body
                    thumbnail
                    media {
                        type
                        thumbnail
                    }
                    tags
                    status
                    visited
                    created
                    reply {
                        editedBy
                        body
                        created
                    }
                    businessName
                }
                total
            }
        }
        """
        
        variables = {
            "input": {
                "businessId": place_id,
                "size": size,
                "sort": sort.upper(),
                "includeContent": True
            }
        }
        
        # Cursor ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜
        if after:
            variables["input"]["after"] = after
        
        print(f"[DEBUG] GraphQL Request - place_id={place_id}, size={size}, after={after[:20] if after else 'None'}...", flush=True)
        
        try:
            logger.info(f"ë°©ë¬¸ì ë¦¬ë·° ì¡°íšŒ ì‹œì‘: place_id={place_id}, size={size}, after={after[:20] if after else 'None'}...")
            async with httpx.AsyncClient(timeout=self.TIMEOUT) as client:
                payload = {"query": query, "variables": variables}
                logger.debug(f"GraphQL ìš”ì²­: {payload}")
                print(f"[DEBUG] GraphQL variables: {variables}", flush=True)
                
                response = await client.post(
                    self.GRAPHQL_URL,
                    json=payload,
                    headers=self.headers
                )
                
                if response.status_code != 200:
                    logger.error(f"ë°©ë¬¸ì ë¦¬ë·° ì¡°íšŒ ì‹¤íŒ¨: status={response.status_code}, body={response.text}")
                    return {"total": 0, "items": [], "has_more": False, "last_cursor": None}
                
                data = response.json()
                
                # ì‘ë‹µ êµ¬ì¡° ë””ë²„ê¹…
                print(f"[DEBUG] Response keys: {list(data.keys())}", flush=True)
                if 'data' in data:
                    print(f"[DEBUG] data keys: {list(data.get('data', {}).keys()) if data.get('data') else 'data is None'}", flush=True)
                
                if "errors" in data:
                    logger.error(f"GraphQL ì—ëŸ¬: {data['errors']}")
                    print(f"[DEBUG] GraphQL errors: {data['errors']}", flush=True)
                    return {"total": 0, "items": [], "has_more": False, "last_cursor": None}
                
                # visitor_reviewsê°€ Noneì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                visitor_reviews = data.get("data", {})
                if visitor_reviews is None:
                    logger.error(f"data is None in response")
                    print(f"[DEBUG] data is None in response", flush=True)
                    return {"total": 0, "items": [], "has_more": False, "last_cursor": None}
                
                visitor_reviews = visitor_reviews.get("visitorReviews")
                if visitor_reviews is None:
                    logger.error(f"visitorReviews is None in response")
                    print(f"[DEBUG] visitorReviews is None in response, full response: {data}", flush=True)
                    return {"total": 0, "items": [], "has_more": False, "last_cursor": None}
                
                items = visitor_reviews.get("items", [])
                total = visitor_reviews.get("total", 0)
                
                # ë§ˆì§€ë§‰ ë¦¬ë·°ì˜ cursor ì¶”ì¶œ
                last_cursor = None
                if items:
                    last_cursor = items[-1].get('cursor')
                    first_id = items[0].get('id', 'N/A')
                    last_id = items[-1].get('id', 'N/A')
                    first_cursor = items[0].get('cursor', 'N/A')
                    print(f"[DEBUG] GraphQL Response - items={len(items)}, first_id={first_id[:16]}, last_id={last_id[:16]}", flush=True)
                    print(f"[DEBUG] Cursors - first={first_cursor[:20] if first_cursor != 'N/A' else 'N/A'}..., last={last_cursor[:20] if last_cursor else 'None'}...", flush=True)
                
                # has_more: cursorê°€ ìˆê³ , sizeë§Œí¼ ê°€ì ¸ì™”ë‹¤ë©´ ë‹¤ìŒì´ ìˆì„ ê°€ëŠ¥ì„±
                has_more = len(items) == size and last_cursor is not None
                
                logger.info(f"ë°©ë¬¸ì ë¦¬ë·° ì¡°íšŒ ì„±ê³µ: place_id={place_id}, total={total}, items_count={len(items)}, has_more={has_more}, last_cursor={last_cursor[:20] if last_cursor else 'None'}...")
                
                return {
                    "total": total,
                    "items": items,
                    "has_more": has_more,
                    "last_cursor": last_cursor
                }
                
        except Exception as e:
            logger.error(f"ë°©ë¬¸ì ë¦¬ë·° ì¡°íšŒ ì˜ˆì™¸: {type(e).__name__} - {str(e)}")
            return {"total": 0, "items": [], "has_more": False, "last_cursor": None}
    
    async def get_blog_reviews(
        self, 
        place_id: str,
        page: int = 1,
        size: int = 20
    ) -> Dict[str, Any]:
        """
        ë¸”ë¡œê·¸ ë¦¬ë·° ì¡°íšŒ (í˜„ì¬ ë„¤ì´ë²„ APIì—ì„œ ì§€ì›í•˜ì§€ ì•ŠìŒ)
        
        Args:
            place_id: ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ID
            page: í˜ì´ì§€ ë²ˆí˜¸ (1ë¶€í„° ì‹œì‘)
            size: í˜ì´ì§€ë‹¹ ë¦¬ë·° ìˆ˜
        
        Returns:
            {
                "total": ì „ì²´ ë¸”ë¡œê·¸ ë¦¬ë·° ìˆ˜,
                "items": [ë¸”ë¡œê·¸ ë¦¬ë·° ëª©ë¡],
                "page": í˜„ì¬ í˜ì´ì§€,
                "has_more": ë‹¤ìŒ í˜ì´ì§€ ì—¬ë¶€
            }
        """
        # ë„¤ì´ë²„ GraphQL APIì—ì„œ blogReviews ì¿¼ë¦¬ê°€ ì œê±°ë¨
        # ì¶”í›„ ëŒ€ì²´ ë°©ë²• í•„ìš” (ì›¹ ìŠ¤í¬ë˜í•‘ ë“±)
        logger.warning(f"ë¸”ë¡œê·¸ ë¦¬ë·° ì¡°íšŒ: í˜„ì¬ ë„¤ì´ë²„ APIì—ì„œ ì§€ì›í•˜ì§€ ì•ŠìŒ (place_id={place_id})")
        return {"total": 0, "items": [], "page": page, "has_more": False}
    
    async def get_all_today_visitor_reviews(
        self,
        place_id: str,
        target_date: Optional[datetime] = None
    ) -> List[Dict[str, Any]]:
        """
        íŠ¹ì • ë‚ ì§œì— ì‘ì„±ëœ ëª¨ë“  ë°©ë¬¸ì ë¦¬ë·° ì¡°íšŒ
        
        Args:
            place_id: ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ID
            target_date: ì¡°íšŒí•  ë‚ ì§œ (Noneì´ë©´ ì˜¤ëŠ˜)
        
        Returns:
            í•´ë‹¹ ë‚ ì§œì— ì‘ì„±ëœ ëª¨ë“  ë¦¬ë·° ëª©ë¡
        """
        if target_date is None:
            target_date = datetime.now()
        
        target_date_str = target_date.strftime("%Y-%m-%d")
        all_reviews = []
        cursor = None
        max_iterations = 10  # ìµœëŒ€ 10íšŒ ë°˜ë³µ
        
        logger.info(f"ë‚ ì§œë³„ ë¦¬ë·° ì¡°íšŒ ì‹œì‘: place_id={place_id}, date={target_date_str}")
        
        for iteration in range(1, max_iterations + 1):
            result = await self.get_visitor_reviews(place_id, size=20, after=cursor)
            items = result.get("items", [])
            
            if not items:
                break
            
            # í•´ë‹¹ ë‚ ì§œì˜ ë¦¬ë·°ë§Œ í•„í„°ë§ (IDì—ì„œ ë‚ ì§œ ì¶”ì¶œ)
            for item in items:
                review_id = item.get("id")
                if review_id:
                    # IDì—ì„œ ë‚ ì§œ ì¶”ì¶œ
                    review_date_str = self.extract_date_from_id(review_id)
                    if review_date_str:
                        if review_date_str == target_date_str:
                            all_reviews.append(item)
                        elif review_date_str < target_date_str:
                            # ë” ì˜¤ë˜ëœ ë¦¬ë·°ê°€ ë‚˜ì˜¤ë©´ ì¤‘ë‹¨
                            logger.info(f"ê³¼ê±° ë¦¬ë·° ë°œê²¬, ì¡°íšŒ ì¤‘ë‹¨: {review_date_str}")
                            return all_reviews
            
            if not result.get("has_more"):
                break
            
            cursor = result.get("last_cursor")
            if not cursor:
                break
        
        logger.info(f"ë‚ ì§œë³„ ë¦¬ë·° ì¡°íšŒ ì™„ë£Œ: {len(all_reviews)}ê°œ")
        return all_reviews
    
    async def get_reviews_by_date_range(
        self,
        place_id: str,
        start_date: datetime,
        end_date: datetime
    ) -> List[Dict[str, Any]]:
        """
        íŠ¹ì • ê¸°ê°„ ë‚´ì— ì‘ì„±ëœ ëª¨ë“  ë°©ë¬¸ì ë¦¬ë·° ì¡°íšŒ
        
        Args:
            place_id: ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ID
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
        
        Returns:
            í•´ë‹¹ ê¸°ê°„ ë‚´ì— ì‘ì„±ëœ ëª¨ë“  ë¦¬ë·° ëª©ë¡
        """
        start_date_str = start_date.strftime("%Y-%m-%d")
        end_date_str = end_date.strftime("%Y-%m-%d")
        all_reviews = []
        
        # ê¸°ê°„ ì¼ìˆ˜ ê³„ì‚°
        date_diff = (end_date - start_date).days + 1  # +1ì€ ì‹œì‘ì¼ í¬í•¨
        
        # ê¸°ê°„ì— ë”°ë¼ ëª©í‘œ ê°œìˆ˜ì™€ í˜ì´ì§€ ìˆ˜ ê²°ì •
        # âš ï¸ Naver APIëŠ” size > 20ì´ë©´ visitorReviewsë¥¼ Noneìœ¼ë¡œ ë°˜í™˜í•¨!
        page_size = 20  # Naver API ìµœëŒ€ í—ˆìš©ì¹˜
        
        if date_diff <= 2:  # ì˜¤ëŠ˜ ë˜ëŠ” ì–´ì œ (1~2ì¼)
            target_reviews = 100
            max_pages = 5  # 20ê°œì”© 5í˜ì´ì§€
        elif date_diff <= 7:  # 7ì¼ê°„
            target_reviews = 400
            max_pages = 20  # 20ê°œì”© 20í˜ì´ì§€
        elif date_diff <= 30:  # 30ì¼ê°„
            target_reviews = 1000
            max_pages = 50  # 20ê°œì”© 50í˜ì´ì§€
        else:  # 30ì¼ ì´ˆê³¼
            target_reviews = 1000
            max_pages = 50
        
        print(f"[DEBUG] get_reviews_by_date_range START: place_id={place_id}, period={start_date_str} ~ {end_date_str}", flush=True)
        try:
            print(f"[DEBUG] ğŸ“Š ê¸°ê°„: {date_diff}ì¼ â†’ ëª©í‘œ={target_reviews}ê°œ, max_pages={max_pages}, page_size={page_size}", flush=True)
        except UnicodeEncodeError:
            print(f"[DEBUG] [STATS] Period: {date_diff}days -> target={target_reviews}, max_pages={max_pages}, page_size={page_size}", flush=True)
        
        page_dates = []  # ê° í˜ì´ì§€ì˜ ë‚ ì§œ ë²”ìœ„ ì¶”ì 
        seen_review_ids = set()  # ì´ë¯¸ ë³¸ ë¦¬ë·° ID ì¶”ì  (ì¤‘ë³µ ë°©ì§€)
        
        cursor = None  # Cursor ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜
        iteration = 1
        
        while iteration <= max_pages:
            print(f"[DEBUG] Iteration {iteration}/{max_pages} requesting (size={page_size}, cursor={cursor[:20] if cursor else 'None'}...)...", flush=True)
            result = await self.get_visitor_reviews(place_id, size=page_size, after=cursor)
            items = result.get("items", [])
            last_cursor = result.get("last_cursor")
            
            print(f"[DEBUG] Iteration {iteration}: items={len(items)}, total={result.get('total', 0)}", flush=True)
            
            if not items:
                print(f"[DEBUG] Iteration {iteration}: No items, stopping", flush=True)
                break
            
            # í•´ë‹¹ ê¸°ê°„ ë‚´ì˜ ë¦¬ë·°ë§Œ í•„í„°ë§ (ë‚ ì§œ ê°ì§€ ë¡œì§ ì‚¬ìš©)
            found_older_review = False
            page_review_dates = []
            page_included = 0
            page_excluded_future = 0
            page_excluded_past = 0
            
            # ìƒì„¸ ë¡œê¹… (ë””ë²„ê¹…ìš©, 100ê°œ ì´í•˜ì¼ ë•Œë§Œ)
            if len(items) <= 100:
                all_ids = [item.get('id') for item in items]
                unique_ids = len(set(all_ids))
                print(f"\n{'='*100}", flush=True)
                try:
                    print(f"[DEBUG] ğŸ“‹ Iteration {iteration} ìˆ˜ì‹  (Total: {len(items)}ê°œ, Unique: {unique_ids})", flush=True)
                except UnicodeEncodeError:
                    print(f"[DEBUG] [LIST] Iteration {iteration} received (Total: {len(items)}, Unique: {unique_ids})", flush=True)
                
                if unique_ids < len(all_ids):
                    try:
                        print(f"[DEBUG] âš ï¸ WARNING: Duplicate IDs found within response!", flush=True)
                    except UnicodeEncodeError:
                        print(f"[DEBUG] [WARNING] Duplicate IDs found within response!", flush=True)
                print(f"{'='*100}\n", flush=True)
            
            # ì²« 2ë²ˆì˜ iterationì—ì„œ ëª¨ë“  ë¦¬ë·° ID ì¶œë ¥ (í˜ì´ì§€ë„¤ì´ì…˜ ê²€ì¦)
            if iteration <= 2:
                print(f"\n[VERIFY] ===== Iteration {iteration} - ì „ì²´ ë¦¬ë·° ID ëª©ë¡ =====", flush=True)
                for idx, item in enumerate(items, 1):
                    review_id = item.get('id', 'N/A')
                    visited = item.get('visited', 'N/A')
                    cursor_preview = item.get('cursor', 'N/A')
                    cursor_preview = cursor_preview[:20] + '...' if cursor_preview != 'N/A' else 'N/A'
                    print(f"  [{idx:2d}] ID: {review_id}, ë°©ë¬¸ì¼: {visited}, cursor: {cursor_preview}", flush=True)
                print(f"[VERIFY] ===== Iteration {iteration} ë =====\n", flush=True)
            
            new_reviews_in_page = 0  # ì´ í˜ì´ì§€ì—ì„œ ìƒˆë¡œ ë°œê²¬í•œ ë¦¬ë·° ìˆ˜
            duplicates_in_page = 0  # ì´ í˜ì´ì§€ì—ì„œ ë°œê²¬í•œ ì¤‘ë³µ ìˆ˜
            
            for item in items:
                review_id = item.get("id")
                if not review_id:
                    continue
                
                # ì¤‘ë³µ ë¦¬ë·° ì²´í¬
                if review_id in seen_review_ids:
                    duplicates_in_page += 1
                    continue  # ì´ë¯¸ ë³¸ ë¦¬ë·°ëŠ” ê±´ë„ˆë›°ê¸°
                
                seen_review_ids.add(review_id)
                new_reviews_in_page += 1
                    
                # visited í•„ë“œì—ì„œ ë‚ ì§œ ì¶”ì¶œ ("1.10.ê¸ˆ" í˜•ì‹)
                visited_str = item.get("visited", "")
                review_date_str = self.parse_naver_date(visited_str)
                
                # visited ì‹¤íŒ¨ì‹œ IDì—ì„œ ì¶”ì¶œ ì‹œë„ (fallback)
                if not review_date_str:
                    review_date_str = self.extract_date_from_id(review_id)
                
                # ì²« iteration ì²« ë¦¬ë·° ë””ë²„ê¹…
                if iteration == 1 and len(page_review_dates) == 0:
                    print(f"[DEBUG] ========== FIRST REVIEW DATA ==========", flush=True)
                    print(f"[DEBUG] ID: {review_id}", flush=True)
                    print(f"[DEBUG] visited (raw): {visited_str}", flush=True)
                    print(f"[DEBUG] Parsed date: {review_date_str}", flush=True)
                    print(f"[DEBUG] =========================================", flush=True)
                
                if not review_date_str:
                    print(f"[DEBUG] Iteration {iteration}: Failed to extract date: visited={visited_str}, id={review_id}", flush=True)
                    continue
                    
                page_review_dates.append(review_date_str)
                
                # ì²« iteration ì²« 3ê°œ ë¦¬ë·°ì˜ ë‚ ì§œ ë¹„êµ ë¡œê·¸
                if iteration == 1 and len(page_review_dates) <= 3:
                    print(f"[DEBUG] Review #{len(page_review_dates)}: date={review_date_str}, range={start_date_str}~{end_date_str}", flush=True)
                    print(f"[DEBUG] Comparison: {start_date_str} <= {review_date_str} <= {end_date_str} = {start_date_str <= review_date_str <= end_date_str}", flush=True)
                
                if start_date_str <= review_date_str <= end_date_str:
                    all_reviews.append(item)
                    page_included += 1
                elif review_date_str > end_date_str:
                    # ì¢…ë£Œì¼ë³´ë‹¤ ìµœì‹  ë¦¬ë·° (ë¯¸ë˜)
                    page_excluded_future += 1
                elif review_date_str < start_date_str:
                    # ì‹œì‘ì¼ë³´ë‹¤ ì˜¤ë˜ëœ ë¦¬ë·° (ê³¼ê±°)
                    page_excluded_past += 1
                    # âš ï¸ ë²”ìœ„ ë‚´ ë¦¬ë·°ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ì¤‘ë‹¨, ì•„ë‹ˆë©´ ê³„ì† (ìµœì‹  ë¦¬ë·°ë¼ë„ ë³´ì—¬ì£¼ê¸° ìœ„í•´)
                    if len(all_reviews) > 0:
                        # ì´ë¯¸ ë²”ìœ„ ë‚´ ë¦¬ë·°ë¥¼ ì°¾ì•˜ìœ¼ë©´ ì¤‘ë‹¨
                        print(f"[DEBUG] Found older review: {review_date_str} < {start_date_str}, stopping", flush=True)
                        found_older_review = True
                        break
                    # ì•„ì§ ë²”ìœ„ ë‚´ ë¦¬ë·°ë¥¼ ëª» ì°¾ì•˜ìœ¼ë©´ ìµœì‹  ë¦¬ë·°ë¼ë„ í¬í•¨
                    all_reviews.append(item)
                    page_included += 1
        
            # Iteration ì²˜ë¦¬ ê²°ê³¼ ë¡œê¹…
            if duplicates_in_page > 0:
                print(f"[DEBUG] Iteration {iteration}: DUPLICATES = {duplicates_in_page}/{len(items)}", flush=True)
            
            if page_review_dates:
                min_date = min(page_review_dates)
                max_date = max(page_review_dates)
                print(f"[DEBUG] Iteration {iteration}: ë‚ ì§œë²”ìœ„={min_date}~{max_date}, ì¶”ì¶œ={new_reviews_in_page}, ì¤‘ë³µ={duplicates_in_page}, í¬í•¨={page_included}, ë¯¸ë˜ì œì™¸={page_excluded_future}, ê³¼ê±°ì œì™¸={page_excluded_past}", flush=True)
                page_dates.append((iteration, min_date, max_date, page_included))
            else:
                print(f"[DEBUG] Iteration {iteration}: ì¶”ì¶œ={new_reviews_in_page}, ì¤‘ë³µ={duplicates_in_page}, í¬í•¨={page_included}", flush=True)
            
            # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´
            # 1. ê³¼ê±° ë¦¬ë·° ë°œê²¬ - ì˜¤ë˜ëœ ë¦¬ë·°ê°€ ë‚˜ì™”ìœ¼ë¯€ë¡œ ì¤‘ë‹¨
            if found_older_review:
                print(f"[DEBUG] STOP: Iteration {iteration} found older review", flush=True)
                break
            
            # 2. ì´ë²ˆ iterationì—ì„œ ìƒˆë¡œìš´ ë¦¬ë·°ê°€ 0ê°œ - ëª¨ë‘ ì¤‘ë³µì´ë¯€ë¡œ ì¤‘ë‹¨
            if new_reviews_in_page == 0 and iteration > 1:
                print(f"[DEBUG] STOP: Iteration {iteration} has no new reviews (all duplicates)", flush=True)
                break
            
            # 3. ì´ë²ˆ iterationì—ì„œ í¬í•¨ëœ ë¦¬ë·°ê°€ 0ê°œ - ë²”ìœ„ ë°– ë¦¬ë·°ë§Œ ìˆì„ ë•Œ
            # ì²« í˜ì´ì§€ê°€ ì•„ë‹ˆê³ , ì´ë¯¸ ì¼ë¶€ ë¦¬ë·°ë¥¼ ì°¾ì•˜ë‹¤ë©´ ì¤‘ë‹¨
            if page_included == 0 and iteration > 1 and len(all_reviews) > 0:
                print(f"[DEBUG] STOP: Iteration {iteration} has 0 included reviews (already found some)", flush=True)
                break
            # ì²« í˜ì´ì§€ì—ì„œ í¬í•¨ëœ ë¦¬ë·°ê°€ 0ê°œë©´ ê³„ì† ì§„í–‰ (ìµœì‹  ë¦¬ë·°ë¼ë„ ë³´ì—¬ì£¼ê¸° ìœ„í•´)
            
            # 4. ëª©í‘œ ê°œìˆ˜ ë‹¬ì„±
            if len(all_reviews) >= target_reviews:
                print(f"[DEBUG] STOP: Target reached ({len(all_reviews)}/{target_reviews})", flush=True)
                break
            
            # 5. ë” ì´ìƒ í˜ì´ì§€ ì—†ìŒ (cursorê°€ ì—†ê±°ë‚˜ has_moreê°€ False)
            if not result.get("has_more") or not last_cursor:
                print(f"[DEBUG] STOP: No more items (has_more={result.get('has_more')}, cursor={last_cursor is not None})", flush=True)
                break
            
            # ë‹¤ìŒ iterationì„ ìœ„í•´ cursor ì—…ë°ì´íŠ¸
            cursor = last_cursor
            iteration += 1
        
        # ìµœì¢… ìš”ì•½
        iterations_processed = len(page_dates)
        print(f"\n{'='*100}", flush=True)
        print(f"[ê²°ê³¼] ê¸°ê°„ë³„ ë¦¬ë·° ì¶”ì¶œ ì™„ë£Œ (Cursor ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜)", flush=True)
        print(f"  ìš”ì²­ ê¸°ê°„: {start_date_str} ~ {end_date_str} ({date_diff}ì¼)", flush=True)
        print(f"  ëª©í‘œ ê°œìˆ˜: {target_reviews}ê°œ", flush=True)
        print(f"  ì²˜ë¦¬ Iterations: {iterations_processed}íšŒ (size={page_size})", flush=True)
        print(f"  ìµœì¢… ê²°ê³¼: {len(all_reviews)}ê°œ", flush=True)
        
        if page_dates:
            print(f"  Iterationë³„ ìš”ì•½:", flush=True)
            for it, min_d, max_d, included in page_dates:
                print(f"    Iteration {it}: {min_d}~{max_d}, í¬í•¨={included}", flush=True)
        
        print(f"{'='*100}\n", flush=True)
        
        if all_reviews:
            logger.info(f"[OK] ê¸°ê°„ë³„ ë¦¬ë·° ì¡°íšŒ ì™„ë£Œ: {len(all_reviews)}ê°œ (ìš”ì²­: {start_date_str}~{end_date_str})")
        else:
            logger.info(f"[WARN] ê¸°ê°„ë³„ ë¦¬ë·° ì¡°íšŒ ì™„ë£Œ: 0ê°œ (ê¸°ê°„: {start_date_str} ~ {end_date_str})")
        
        return all_reviews
    
    def parse_naver_date(self, date_str: str) -> Optional[str]:
        """
        ë„¤ì´ë²„ ë‚ ì§œ í˜•ì‹ íŒŒì‹±: "1.10.ê¸ˆ" â†’ "2026-01-10"
        
        Args:
            date_str: "ì›”.ì¼.ìš”ì¼" í˜•ì‹ (ì˜ˆ: "1.10.ê¸ˆ", "12.25.ìˆ˜")
        
        Returns:
            ISO í˜•ì‹ ë‚ ì§œ ë¬¸ìì—´ (YYYY-MM-DD)
        """
        try:
            if not date_str or date_str == "":
                return None
            
            # "1.10.ê¸ˆ" â†’ ["1", "10", "ê¸ˆ"]
            parts = date_str.split(".")
            if len(parts) < 2:
                return None
            
            month = int(parts[0])
            day = int(parts[1])
            
            # í˜„ì¬ ë…„ë„ ê°€ì • (KST ê¸°ì¤€)
            KST = pytz.timezone('Asia/Seoul')
            now = datetime.now(KST)
            current_year = now.year
            
            # ë‚ ì§œ ìƒì„±
            review_date = datetime(current_year, month, day)
            
            # ë¯¸ë˜ ë‚ ì§œë¼ë©´ ì‘ë…„ìœ¼ë¡œ ë³€ê²½
            if review_date.replace(tzinfo=None) > now.replace(tzinfo=None):
                review_date = datetime(current_year - 1, month, day)
            
            return review_date.strftime("%Y-%m-%d")
        except Exception as e:
            logger.debug(f"ë„¤ì´ë²„ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨: {date_str}, {str(e)}")
            return None
    
    def extract_date_from_id(self, review_id: str) -> str:
        """
        ë¦¬ë·° ID(MongoDB ObjectId)ì—ì„œ ì‘ì„± ë‚ ì§œ ì¶”ì¶œ
        
        Args:
            review_id: ë„¤ì´ë²„ ë¦¬ë·° ID (24ì hex string)
        
        Returns:
            ISO í˜•ì‹ ë‚ ì§œ ë¬¸ìì—´ (YYYY-MM-DD, KST ê¸°ì¤€)
        """
        try:
            # ObjectIdì˜ ì²« 8ìëŠ” Unix timestamp (hex)
            timestamp_hex = review_id[:8]
            timestamp = int(timestamp_hex, 16)
            
            # UTC ì‹œê°„ìœ¼ë¡œ ë³€í™˜ í›„ KSTë¡œ ë³€ê²½
            dt_utc = datetime.fromtimestamp(timestamp, tz=pytz.utc)
            KST = pytz.timezone('Asia/Seoul')
            dt_kst = dt_utc.astimezone(KST)
            return dt_kst.strftime("%Y-%m-%d")
        except Exception as e:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
            logger.debug(f"ë¦¬ë·° ID ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨: {review_id}, {str(e)}")
            return None
    
    def parse_review_data(self, review: Dict[str, Any], review_type: str) -> Dict[str, Any]:
        """
        ë„¤ì´ë²„ ë¦¬ë·° ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ í‘œì¤€ í¬ë§·ìœ¼ë¡œ ë³€í™˜
        
        Args:
            review: ë„¤ì´ë²„ API ë¦¬ë·° ì›ë³¸ ë°ì´í„°
            review_type: 'visitor' ë˜ëŠ” 'blog'
        
        Returns:
            íŒŒì‹±ëœ ë¦¬ë·° ë°ì´í„°
        """
        if review_type == "visitor":
            author = review.get("author", {})
            media = review.get("media", [])
            images = [m.get("thumbnail") for m in media if m.get("type") == "image"]
            
            review_id = str(review.get("id", ""))
            # visited í•„ë“œì—ì„œ ë‚ ì§œ ì¶”ì¶œ ("1.10.ê¸ˆ" í˜•ì‹)
            visited_str = review.get("visited", "")
            review_date = self.parse_naver_date(visited_str)
            
            # visited ì‹¤íŒ¨ì‹œ IDì—ì„œ ì¶”ì¶œ ì‹œë„
            if not review_date:
                review_date = self.extract_date_from_id(review_id)
            
            # ì‘ì„±ì ë¦¬ë·° ìˆ˜ëŠ” Naver APIì—ì„œ ì œê³µí•˜ì§€ ì•ŠìŒ (reviewCount í•„ë“œ ì—†ìŒ)
            # í–¥í›„ ê°œì„ : ì‘ì„±ì í”„ë¡œí•„ í˜ì´ì§€ í¬ë¡¤ë§ ë˜ëŠ” ë‹¤ë¥¸ ë°©ë²• í•„ìš”
            author_review_count = 0
            is_power_reviewer = False
            
            return {
                "naver_review_id": review_id,
                "review_type": "visitor",
                "author_name": author.get("nickname", ""),
                "author_id": str(author.get("id", "")),
                "author_review_count": author_review_count,
                "is_power_reviewer": is_power_reviewer,
                "is_receipt_review": False,  # tags í•„ë“œê°€ Noneì´ë¯€ë¡œ íŒë‹¨ ë¶ˆê°€
                "is_reservation_review": False,  # tags í•„ë“œê°€ Noneì´ë¯€ë¡œ íŒë‹¨ ë¶ˆê°€
                "rating": float(review.get("rating")) if review.get("rating") is not None else None,
                "content": review.get("body", ""),
                "images": images,
                "review_date": review_date,  # IDì—ì„œ ì¶”ì¶œí•œ ë‚ ì§œ
                "like_count": 0,  # heart í•„ë“œ ì œê±°ë¨
                "comment_count": 1 if review.get("reply") else 0
            }
        
        elif review_type == "blog":
            return {
                "naver_review_id": str(review.get("id", "")),
                "review_type": "blog",
                "author_name": review.get("author", ""),
                "author_id": "",
                "author_review_count": 0,
                "is_power_reviewer": False,
                "is_receipt_review": False,
                "is_reservation_review": False,
                "rating": None,
                "content": review.get("summary", "") or review.get("title", ""),
                "images": [review.get("thumbnail")] if review.get("thumbnail") else [],
                "review_date": review.get("created"),
                "like_count": 0,
                "comment_count": 0
            }
        
        return {}
    
    async def get_place_info(
        self, 
        place_id: str, 
        store_name: str = None,
        x: str = None,
        y: str = None
    ) -> Dict[str, Any]:
        """
        ë§¤ì¥ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ë¦¬ë·° ìˆ˜, í‰ì  ë“±)
        
        places ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ í™œìš©í•˜ì—¬ ë§¤ì¥ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
        ë§¤ì¥ëª…ìœ¼ë¡œ ê²€ìƒ‰ í›„ place_idë¥¼ ë§¤ì¹­í•©ë‹ˆë‹¤.
        
        Args:
            place_id: ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ID
            store_name: ë§¤ì¥ëª… (ê²€ìƒ‰ì— ì‚¬ìš©)
            x: ê²½ë„ (ì„ íƒ)
            y: ìœ„ë„ (ì„ íƒ)
        
        Returns:
            {
                "place_id": ë§¤ì¥ ID,
                "name": ë§¤ì¥ëª…,
                "visitor_review_count": ë°©ë¬¸ì ë¦¬ë·° ìˆ˜,
                "blog_review_count": ë¸”ë¡œê·¸ ë¦¬ë·° ìˆ˜,
                "rating": í‰ì ,
                "description": í•œì¤„í‰ (ë¹ˆ ë¬¸ìì—´, APIì—ì„œ ì œê³µí•˜ì§€ ì•ŠìŒ)
            }
        """
        query = """
        query getPlacesList($input: PlacesInput) {
            places(input: $input) {
                items {
                    id
                    name
                    visitorReviewCount
                    blogCafeReviewCount
                    visitorReviewScore
                    category
                    address
                    roadAddress
                }
            }
        }
        """
        
        # ë§¤ì¥ëª…ìœ¼ë¡œ ê²€ìƒ‰ (place_idë¡œëŠ” ê²€ìƒ‰ ì•ˆ ë¨)
        # store_nameì´ ì—†ìœ¼ë©´ place_idë¡œ ì‹œë„
        search_query = store_name if store_name else place_id
        
        # ì¢Œí‘œ ì„¤ì • (stores í…Œì´ë¸” ê°’ ìš°ì„ , ì—†ìœ¼ë©´ ì„œìš¸ ê¸°ì¤€)
        coord_x = x if x else "127.0276"
        coord_y = y if y else "37.4979"
        
        variables = {
            "input": {
                "query": search_query,
                "start": 1,
                "display": 10,  # ì¤‘ë³µ ê²°ê³¼ ëŒ€ë¹„
                "deviceType": "mobile",
                "x": coord_x,
                "y": coord_y
            }
        }
        
        try:
            logger.info(f"ë§¤ì¥ ì •ë³´ ì¡°íšŒ ì‹œì‘: place_id={place_id}, store_name='{store_name}', x={coord_x}, y={coord_y}")
            
            # ë§¤ì¥ëª…ì´ ì—†ìœ¼ë©´ ë¦¬ë·°ì—ì„œ ê°€ì ¸ì˜¤ê¸° ì‹œë„
            if not store_name or store_name.strip() == "":
                logger.warning(f"[WARN] ë§¤ì¥ëª… ì—†ìŒ. ë¦¬ë·°ì—ì„œ ë§¤ì¥ëª… ì¶”ì¶œ ì‹œë„")
                try:
                    visitor_result = await self.get_visitor_reviews(place_id, size=1)
                    if visitor_result and visitor_result.get("items"):
                        store_name = visitor_result["items"][0].get("businessName", "")
                        logger.info(f"[OK] ë¦¬ë·°ì—ì„œ ë§¤ì¥ëª… ì¶”ì¶œ ì„±ê³µ: '{store_name}'")
                        search_query = store_name
                except Exception as e:
                    logger.error(f"ë¦¬ë·°ì—ì„œ ë§¤ì¥ëª… ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
                    # ì—¬ì „íˆ ë§¤ì¥ëª…ì´ ì—†ìœ¼ë©´ place_id ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì‹¤íŒ¨í•  í™•ë¥  ë†’ìŒ)
                    search_query = place_id
            
            async with httpx.AsyncClient(timeout=self.TIMEOUT) as client:
                response = await client.post(
                    self.GRAPHQL_URL,
                    json={
                        "operationName": "getPlacesList",
                        "variables": variables,
                        "query": query
                    },
                    headers=self.headers
                )
                
                if response.status_code != 200:
                    logger.error(f"ë§¤ì¥ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: status={response.status_code}")
                    return None
                
                data = response.json()
                
                if "errors" in data:
                    logger.error(f"GraphQL ì—ëŸ¬: {data['errors']}")
                    return None
                
                items = data.get("data", {}).get("places", {}).get("items", [])
                
                logger.info(f"ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(items)}")
                if items:
                    for idx, item in enumerate(items):
                        logger.info(f"  [{idx+1}] {item.get('name')} (ID: {item.get('id')})")
                
                if not items:
                    logger.warning(f"ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ: query={search_query}, place_id={place_id}")
                    return None
                
                # place_idê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í•­ëª© ì°¾ê¸°
                place = None
                for item in items:
                    if str(item.get("id")) == str(place_id):
                        place = item
                        logger.info(f"[OK] place_id ì¼ì¹˜: {item.get('name')} (ID: {item.get('id')})")
                        break
                
                # ì¼ì¹˜í•˜ëŠ” í•­ëª©ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ í•­ëª© ì‚¬ìš© (ë§¤ì¥ëª…ì´ ìœ ì‚¬í•˜ë‹¤ê³  ê°€ì •)
                if not place and items:
                    place = items[0]
                    logger.warning(f"[WARN] place_id ë¶ˆì¼ì¹˜. ì²« ë²ˆì§¸ ê²°ê³¼ ì‚¬ìš©: {place.get('name')} (ID: {place.get('id')}) - ìš”ì²­í•œ ID: {place_id}")
                
                if not place:
                    logger.error(f"[ERROR] ë§¤ì¥ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: place_id={place_id}")
                    return None
                
                # ìˆ«ì íŒŒì‹± í—¬í¼ í•¨ìˆ˜
                def parse_int(value):
                    """ì‰¼í‘œê°€ í¬í•¨ëœ ë¬¸ìì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜"""
                    if value is None:
                        return 0
                    if isinstance(value, int):
                        return value
                    try:
                        return int(str(value).replace(',', ''))
                    except (ValueError, AttributeError):
                        return 0
                
                def parse_float(value):
                    """ë¬¸ìì—´ì„ floatë¡œ ë³€í™˜"""
                    if value is None:
                        return None
                    if isinstance(value, (int, float)):
                        return float(value)
                    try:
                        return float(str(value).replace(',', ''))
                    except (ValueError, AttributeError):
                        return None
                
                result = {
                    "place_id": str(place.get("id", place_id)),
                    "name": place.get("name", ""),
                    "category": place.get("category", ""),
                    "address": place.get("address", ""),
                    "roadAddress": place.get("roadAddress", ""),
                    "visitor_review_count": parse_int(place.get("visitorReviewCount")),
                    "blog_review_count": parse_int(place.get("blogCafeReviewCount")),
                    "visitorReviewScore": parse_float(place.get("visitorReviewScore")),
                    "rating": parse_float(place.get("visitorReviewScore")),  # í˜¸í™˜ì„±
                    "description": ""
                }
                
                logger.info(f"ë§¤ì¥ ì •ë³´ ì¡°íšŒ ì„±ê³µ: {result}")
                return result
                
        except Exception as e:
            logger.error(f"ë§¤ì¥ ì •ë³´ ì¡°íšŒ ì˜ˆì™¸: {type(e).__name__} - {str(e)}")
            return None


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
naver_review_service = NaverReviewService()
