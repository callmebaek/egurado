"""
ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬
ìë™ ë¦¬ë·° ìˆ˜ì§‘, ìˆœìœ„ í™•ì¸ ë“±
"""
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from datetime import datetime, date
import logging

from app.core.database import get_supabase_client
from app.services.naver_crawler import crawl_naver_reviews
from app.services.naver_rank_service import rank_service

logger = logging.getLogger(__name__)

# ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤
scheduler = AsyncIOScheduler()


async def sync_all_stores_reviews():
    """
    ëª¨ë“  í™œì„± ë§¤ì¥ì˜ ë¦¬ë·° ìë™ ìˆ˜ì§‘
    ë§¤ì¼ ì˜¤ì „ 6ì‹œ ì‹¤í–‰
    """
    try:
        print(f"[{datetime.now()}] [SYNC] Starting review collection for all stores")
        
        supabase = get_supabase_client()
        
        # í™œì„± ìƒíƒœì˜ ë„¤ì´ë²„ ë§¤ì¥ ì¡°íšŒ
        result = supabase.table("stores").select("id, place_id, store_name").eq(
            "platform", "naver"
        ).eq("status", "active").execute()
        
        if not result.data:
            print("[WARN] No active stores found")
            return
        
        stores = result.data
        print(f"[INFO] {len(stores)} stores scheduled for review collection")
        
        for store in stores:
            try:
                print(f"ğŸ“ ë§¤ì¥ '{store['store_name']}' ë¦¬ë·° ìˆ˜ì§‘ ì¤‘...")
                reviews = await crawl_naver_reviews(store["id"], store["place_id"])
                print(f"[OK] '{store['store_name']}': {len(reviews)} reviews collected")
            except Exception as e:
                print(f"[ERROR] '{store['store_name']}' review collection failed: {e}")
                continue
        
        print(f"[{datetime.now()}] [SYNC] Review collection completed")
        
    except Exception as e:
        print(f"[ERROR] Review collection scheduler error: {e}")


async def check_all_keywords_rank():
    """
    ë“±ë¡ëœ ëª¨ë“  í‚¤ì›Œë“œ ìˆœìœ„ ìë™ í™•ì¸
    ë§¤ì¼ ì˜¤ì „ 7ì‹œ ì‹¤í–‰
    
    - ëª¨ë“  ë“±ë¡ëœ í‚¤ì›Œë“œì˜ ìˆœìœ„ ì²´í¬
    - keywords í…Œì´ë¸” ì—…ë°ì´íŠ¸ (current_rank, previous_rank)
    - rank_history í…Œì´ë¸”ì— ì˜¤ëŠ˜ ë‚ ì§œ ë°ì´í„°ë§Œ ìœ ì§€
    """
    try:
        logger.info(f"[{datetime.now()}] ğŸ” í‚¤ì›Œë“œ ìˆœìœ„ ìë™ í™•ì¸ ì‹œì‘")
        
        supabase = get_supabase_client()
        
        # ëª¨ë“  í‚¤ì›Œë“œ ì¡°íšŒ (store ì •ë³´ í¬í•¨)
        result = supabase.table("keywords").select(
            "id, keyword, store_id, current_rank, stores(place_id, store_name)"
        ).execute()
        
        if not result.data:
            logger.warning("[WARN] No keywords registered")
            return
        
        keywords = result.data
        logger.info(f"[INFO] {len(keywords)} keywords scheduled for rank check")
        
        success_count = 0
        error_count = 0
        
        for kw in keywords:
            try:
                keyword_id = kw["id"]
                keyword_text = kw["keyword"]
                store_id = kw["store_id"]
                current_rank = kw.get("current_rank")
                
                # store ì •ë³´ ì¶”ì¶œ
                if not kw.get("stores"):
                    logger.warning(f"[SKIP] '{keyword_text}': No store data found")
                    continue
                
                place_id = kw["stores"]["place_id"]
                store_name = kw["stores"]["store_name"]
                
                logger.info(f"ğŸ” '{keyword_text}' (ë§¤ì¥: {store_name}) ìˆœìœ„ í™•ì¸ ì¤‘...")
                
                # ìˆœìœ„ ì²´í¬ (ìµœëŒ€ 300ê°œ)
                rank_result = await rank_service.check_rank(
                    keyword=keyword_text,
                    target_place_id=place_id,
                    max_results=300
                )
                
                new_rank = rank_result["rank"]
                found = rank_result["found"]
                
                # keywords í…Œì´ë¸” ì—…ë°ì´íŠ¸
                supabase.table("keywords").update({
                    "previous_rank": current_rank,
                    "current_rank": new_rank,
                    "last_checked_at": datetime.utcnow().isoformat()
                }).eq("id", keyword_id).execute()
                
                # rank_history ì²˜ë¦¬ (ì˜¤ëŠ˜ ë‚ ì§œ ë°ì´í„°ë§Œ ìœ ì§€)
                today = date.today()
                
                # 1. ì˜¤ëŠ˜ ë‚ ì§œì˜ ê¸°ì¡´ ê¸°ë¡ ì‚­ì œ
                supabase.table("rank_history").delete().eq(
                    "keyword_id", keyword_id
                ).gte(
                    "checked_at", today.isoformat()
                ).lt(
                    "checked_at", (today.replace(day=today.day + 1)).isoformat() 
                    if today.day < 28 else today.isoformat()
                ).execute()
                
                # 2. ìƒˆë¡œìš´ ê¸°ë¡ ì¶”ê°€
                supabase.table("rank_history").insert({
                    "keyword_id": keyword_id,
                    "rank": new_rank,
                    "checked_at": datetime.utcnow().isoformat()
                }).execute()
                
                if found and new_rank:
                    rank_change = ""
                    if current_rank and new_rank:
                        change = current_rank - new_rank
                        if change > 0:
                            rank_change = f" (â†‘{change})"
                        elif change < 0:
                            rank_change = f" (â†“{abs(change)})"
                    
                    logger.info(
                        f"[OK] '{keyword_text}' (ë§¤ì¥: {store_name}): "
                        f"Rank #{new_rank}{rank_change}"
                    )
                else:
                    logger.warning(
                        f"[NOT FOUND] '{keyword_text}' (ë§¤ì¥: {store_name}): "
                        f"ìˆœìœ„ê¶Œ ë°– (ìƒìœ„ 40ê°œ ë‚´ ë¯¸í¬í•¨)"
                    )
                
                success_count += 1
                    
            except Exception as e:
                error_count += 1
                logger.error(
                    f"[ERROR] '{kw.get('keyword', 'Unknown')}' rank check failed: {str(e)}",
                    exc_info=True
                )
                continue
        
        logger.info(
            f"[{datetime.now()}] [CHECK] í‚¤ì›Œë“œ ìˆœìœ„ í™•ì¸ ì™„ë£Œ - "
            f"ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {error_count}"
        )
        
    except Exception as e:
        logger.error(f"[ERROR] Rank check scheduler error: {str(e)}", exc_info=True)


def start_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"""
    # ë§¤ì¼ ì˜¤ì „ 6ì‹œ: ë¦¬ë·° ìˆ˜ì§‘
    scheduler.add_job(
        sync_all_stores_reviews,
        CronTrigger(hour=6, minute=0),
        id="sync_reviews",
        name="ì „ì²´ ë§¤ì¥ ë¦¬ë·° ìë™ ìˆ˜ì§‘",
        replace_existing=True
    )
    
    # ë§¤ì¼ ì˜¤ì „ 3ì‹œ: í‚¤ì›Œë“œ ìˆœìœ„ í™•ì¸ (ë¦¬ë·° ìˆ˜ì§‘ ì „ì— ì‹¤í–‰)
    scheduler.add_job(
        check_all_keywords_rank,
        CronTrigger(hour=3, minute=0),
        id="check_ranks",
        name="í‚¤ì›Œë“œ ìˆœìœ„ ìë™ í™•ì¸",
        replace_existing=True
    )
    
    scheduler.start()
    logger.info("[OK] Scheduler started")
    logger.info("  - Rank check: 3 AM daily (KST)")
    logger.info("  - Review sync: 6 AM daily (KST)")


def stop_scheduler():
    """ìŠ¤ì¼€ì¤„ëŸ¬ ì¤‘ì§€"""
    scheduler.shutdown()
    print("[OK] Scheduler stopped")


